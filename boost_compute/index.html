<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Boost Compute</title>

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
			    <!-- ###################################################################
				     ##################################################################-->
				<section data-markdown>
					#Boost Compute
					#### Code Chat November 2016
					Anton Piccardo-Selg
				</section>
				<!-- ##################################################################
				     ##################################################################-->
				<!-- What is Boost Compute -->
				<section name ="what_is">
					<section>
					<h2> What is Boost Compute?</h2>
						<ul>
						<li> heterogenous-computing library for C++ based on <b>OpenCL</b> </li>
						<li> essentially thin C++ wrapper over the OpenCL API </li>
						<li> Windows, Mac, Linux </li>
						<li> Header only library (almost)</li>
						<li> Added to Boost (1.61) in April 2016 </li>
						</ul>
					</section>
					<section>
						<img src="boost_compute_architecture.jpg" height="100%" width="100%" style="background:none; border:none; box-shadow:none;">
						<font size="5">
						<div style="text-align:left">
							Source: <a href="http://www.iwocl.org/wp-content/uploads/iwocl-2016-boost-compute.pdf"> IWOCL Talk Jakub Szuppe </a>
						</div>
						</font>
					</section>
				</section>
				<!-- ##################################################################
				     ##################################################################-->
				<!-- Basic OpenCL -->
				<section name ="open_cl_basics">
				<section>
					<h2>OpenCL Concepts</h2>
				</section>
				<section>
					<h5>OpenCL Class Diagram </h5>
					<img src="open_cl_class_diagram.jpg" height="60%" width="60%" style="background:none; border:none; box-shadow:none;">
					<font size="5">
					<div style="text-align:left">
						Source: <a href="https://www.khronos.org/files/opencl20-quick-reference-card.pdf"> Khronos OpenCL 2.0 Quick Reference Card </a>
					</div>
					</font>
				</section>
				<section style="width:110%">
					<font size="6">
					<p style="text-align:left">Platform: </p>
					<ul>
						<li> Actual OpenCL implementation (Vendor and version specific)</li>
						<li> Example: Intel(R) OpenCL, Experimental OpenCL 2.1 CPU Only Platform</li>
					</ul>
				</font>
				<div class="fragment">
				<font size="6">
				<p style="text-align:left">Device: </p>
				<img src="memory_model.png" height="50%" width="50%" style="background:none; border:none; box-shadow:none;">
				</font>
				<font size="5">
				<div style="text-align:left">
					Source: <a href="https://www.khronos.org/files/opencl20-quick-reference-card.pdf"> Khronos OpenCL 2.0 Quick Reference Card </a>
				</div>
				</font>
				</div>
				</section>
				<section>
					<font size="6">
					<p style="text-align:left">Context: </p>
					<ul>
						<li> Host-device interaction </li>
						<li> Management of memory objects and keeping track of kernels</li>
					</ul>
					<div class="fragment">
					<p style="text-align:left">Command Queue: </p>
					<ul>
						<li> Communciation with compute device</li>
						<li> Data transfer and kernel execution</li>
					</ul>
					</div>
					<!--
					<ul>
						<li> Communciation with compute device</li>
						<li> Data transfer + Kernel execution</li>
					</ul>

					<p style="text-align:left">Program + Kernel: </p>
					<ul>
						<li> Program contains Kernels</li>
						<li> Runtime compilation (but can cache or load binaries in specialized situations).</li>
						<li> Kernel is a function which runs in parallel on compute device</li>
						<li> Kernels written in OpenCL C</li>
					</ul>
				 -->
				  </font>
				</section>
				<section>
					<font size="6">
					<p style="text-align:left">Simple Kernel for addition: </p>
					</font>
					<pre style="width:100%"><code class="cpp" data-trim contenteditable >
__kernel void add(__global float* a, __gloabl float* b, __global float* c) {
  const uint i = get_global_id(0);
  c[i] = a[i] + b[i];
}
					</code></pre>
					<font size="6">
					<p style="text-align:left">OpenCL C API Example: </p>
					</font>
<pre style="width:100%"><code class="cpp" data-trim contenteditable >
...
result = clBuildProgram(program, 0, NULL, NULL, NULL, NULL);
if (result != CL_SUCCESS) {
...
}
</code></pre>
				</section>
			</section>
				<!-- ##################################################################
				     ##################################################################-->
				<!-- How to integrate boost into your project -->
				<section name ="why_boost_compute" style="width:140%; left:-20%">
				 <section>
				 <h2> Getting Started </h2>
			 </section>
			 <section>
				 	<ol>
						<li> Get the OpenCL implementation for your devices, ie from Intel, AMD, ...
							<ul>
								<li>You should have a <code>cl.hpp</code>/<code>cl.h</code> and a corresponding OpenCL library.</li>
							</ul>
						</li>
					<div class="fragment">
						<li> Get Boost >1.61 </li>
					</div>
					<div class="fragment">
						<li> Make OpenCL available to your build
							<ul>
								<li> <code>find_package(OpenCL REQUIRED)</code> </li>
								<li> <code>include_directories(SYSTEM ${OpenCL_INCLUDE_DIRS})</code> </li>
								<li> <code>target_link_libraries(EXECUTABLE ${OpenCL_LIBRARIES})</code></li>
							</ul>
						</li>
					</div>
					<div class="fragment">
						<li>Include via:
							<ul>
								<li> <code>&ltboost/compute.hpp&gt</code> or </li>
								<li> <code>&ltboost/compute/xxx.hpp&gt</code></li>
							</ul>
						</li>
					</div>
					</ol>
				</section>
				</section>
				<!-- ###################################################################
				     ##################################################################-->
				<section name ="hello_boost_compute">
					<section>
					<h2> Using the High-Level API</h2>
					</section>
					<section name="initialize_algorihtm">
						<h5> Example: Sorting a vector</h5>
			<font size="6">
			<p style="text-align:left">Setup (simple): </p>
			<ul>
				<li> Get a compute device </li>
				<li> Setup a context </li>
				<li> Create a command queue for the compute device </li>
			</ul>
			</font>
<div class="fragment">
<pre style="width:100%"><code class="cpp" data-trim contenteditable >
#include &ltboost/compute.hpp&gt
#include &ltiostream&gt
#include &ltvector&gt

namespace compute = boost::compute;

int main() {
auto device = compute::system::default_device();
std::cout &lt&lt device.name() &lt&lt std::endl; // Intel(R) HD Graphics 4600
compute::context context(device);
compute::command_queue command_queue(context, device);

# Create a sample vector on the host
// generate random data on the host
const size_t host_vector_size = 10000;
std::vector&ltfloat&gt host_vector(host_vector_size);
std::generate(host_vector.begin(), host_vector.end(), rand);

</code></pre>
</div>
					</section>
					<section>
						<h5> Example: Sorting a vector</h5>
						<font size="6">
						<p style="text-align:left">Transfer from host to device: </p>
						<ul style="text-align:left">
							<li> Create a buffer</li>
							<li> Copy from host to device</li>
						</ul>
						</font>
				  <div class="fragment">
<pre style="width:100%"><code class="cpp" data-trim contenteditable >
compute::vector&ltfloat&gt device_vector(host_vector.size(), context);

compute::copy(host_vector.begin(),
              host_vector.end(),
              device_vector.begin(),
              queue);
</code></pre>
					</div>
					</section>
					<section>
						<h5> Example: Sorting a vector</h5>
						<font size="6">
						<p style="text-align:left">Perform the sorting: </p>
						<ul style="text-align:left">
							<li> Run the algorihtm</li>
							<li> Transfer data back to host</li>
						</ul>
						</font>
<div class="fragment">

<pre style="width:100%"><code class="cpp" data-trim contenteditable >
compute::sort(device_vector.begin(), device_vector.end(), queue);

compute::copy(device_vector.begin(),
              device_vector.end(),
              host_vector.begin(),
              queue);

return 0;
}
</code></pre>
</div>
					</section>
					<section>
						<h5><a href="http://www.boost.org/doc/libs/1_61_0/libs/compute/doc/html/boost_compute/reference.html#boost_compute.reference.api_overview">compute::algorithm API</a></h5>
					</section>
					<section>
					<h5> Other features</h5>
					<font size="6">
					<p style="text-align:left">Functions, Closures, Lambdas: </p>
					</font>
					<pre style="width:120%"><code class="cpp" data-trim contenteditable >
float cutoff = 42.0;
BOOST_COMPUTE_CLOSURE(bool, is_smaller, (float value), (cutoff),
{
    return value &lt cutoff;
});

auto all_elements_smaller =
         boost::compute::all_of(device_vector.begin(),
                                device_vector.end(),
                                is_smaller, queue);

					</code></pre>
					<div class="fragment">
					<pre style="width:120%"><code class="cpp" data-trim contenteditable >
boost::compute::function&ltbool(float)&gt is_smaller_2 =
                                return boost::compute::lambda::_1 &lt cutoff;
auto all_elements_smaller2 =
          boost::compute::all_of(vectors.begin(),
                                 vectors.end(),
                                 is_smaller_2,
                                 queue);

					</code></pre>
				  </div>
					</section>
					<section>
						<h5> Other features</h5>
						<font size="6">
						<ul>
							<li> Asynchronous data transfer</li>
							<li> Vectorized data </li>
							<li> Iterators (e.g. zip iterator) </li>
							<li> ... </li>
						</font>
					</section>
				</section>
				<!-- ###################################################################
						 ##################################################################-->
				<section name ="low_level_algorithms">
					<section>
					<h2> Low-level approach</h2>
					</section>
					<section>
						<font size="6">
						<p style="text-align:left">Example: Matrix Multiplication</p>
						</font>
<pre style="width:100%;"><code class="cpp" data-trim contenteditable>
...
for(size_t row = 0; row < rows; ++row) {
  for(size_t column = 0; j < columns; ++column) {
    for(size_t inner = 0;  < inner_dim; ++inner) {
      mult[row][column] += a[row][inner] * b[inner][column];
    }
  }
}
...
</code></pre>
<font size="6" >
						<div class="fragment" style="text-align:left">
						<ul>
							<li> Define kernel for matrix multiplication</li>
							<li> Setup a OpenCL environment </li>
							<li> Build program object </li>
							<li> Execute the matrix multiplication kernel</li>
						</font>
					</div>
					</section>
					<section>
						<font size="6">
						<p style="text-align:left">Define Kernel</p>
						</font>
<pre style="width:110%;"><code class="cpp" data-trim contenteditable>
const char matrix_multiplication_source[] = BOOST_COMPUTE_STRINGIZE_SOURCE(
__kernel void matrix_mult(__global const float *a, __global const float* b,
                          __global float* c, int rows,  int columns,  int inners)
{
  const uint row = get_global_id(0);
  const uint column = get_global_id(1);

  const uint current_index_c = row*columns + column;
  const uint current_index_a_offset = row*rows;

  float value = 0;
  for (size_t index = 0; index < inners; ++index) {
    value += a[current_index_a_offset + index]*b[column*index + row];
  }
  c[current_index_c] = value;
}
);
</code></pre>
					<font size="6">
					<div class="fragment" style="text-align:left">
					  <ul >
						 <li>Can use OpenCL program caching</li>
						 <li>Requires Boost.Filesystem </li>
						 <li><code> BOOST_COMPUTE_USE_OFFLINE_CACHE </code> </li>
					  </ul>
				  </div>
				  </font>
					</section>
					<section>
					<font size="6">
					<p style="text-align:left">Setup</p>
					<ul>
						<li>Create device, context and command queue as previously</li>
						<li>Copy the data to a device vector</li>
						<li>Asynchronous</li>
					</ul>
				  </font>
<pre style="width:100%"><code class="cpp" data-trim contenteditable >
...
// Create device
auto device = compute::system::default_device();
auto context = compute::context(device);
compute::command_queue command_queue(context, device);

// Transfer data from host to device
compute::vector&ltfloat&gt device_a(number_of_elements_a, context);
compute::vector&ltfloat&gt device_b(number_of_elements_b, context);
compute::vector&ltfloat&gt device_c(number_of_elements_c, context);
auto copy_a = boost::compute::copy_async(host_a.begin(), host_a.end(),
                                         device_a.begin(), command_queue);
auto copy_b = boost::compute::copy_async(host_b.begin(), host_b.end(),
                                         device_b.begin(), command_queue);
</code></pre>
					</section>
					<section>
						<font size="6">
						<p style="text-align:left">Build program</p>
						<ul>
							<li>Build program and get the kernel</li>
							<li>Set the kernel arguments and the range</li>
						</ul>
						</font>
<pre style="width:110%"><code class="cpp" data-trim contenteditable >
// Compile the program
auto matrix_mult_program = compute::program::create_with_source(
                                        matrix_multiplication_source, context);
matrix_mult_program.build();
compute::kernel matrix_mult_kernel(matrix_mult_program, "matrix_mult");

// Wait until the input data has been copied
copy_a.wait();
copy_b.wait();

// Set the kernel argument and run it
matrix_mult_kernel.set_args(device_a.get_buffer(), device_b.get_buffer(),
                            device_c.get_buffer(), rows, columns, inner_dim);
</code></pre>
				</section>
				<section>
					<font size="6">
					<p style="text-align:left">Execute the kernel</p>
					<ul>
						<li>Enque the Kernel </li>
						<li>Set the work size</li>
					</ul>
					</font>
<pre style="width:110%"><code class="cpp" data-trim contenteditable >
// Run computation on GPU
command_queue.enqueue_nd_range_kernel(matrix_mult_kernel,
                                compute::dim(0, 0) /*global work offst*/,
                                compute::dim(rows, columns) /*global work size*/,
                                compute::dim(1, 1) /*local work size*/);
// Get the output back to the host
compute::copy(device_c.begin(), device_c.end(), host_c.begin(), command_queue);
...
</code></pre>
				</section>
				</section>
				<!-- ###################################################################
				     ##################################################################-->
				<!-- Performance -->
				<section>
				<section>
					<h3>Performance</h3>
				</section>
				<section>
					<font size="8">
					<div style="text-align:left">
						Sort
					</div>
					</font>
					<img src="boost_compute_performance.png" height="100%" width="100%" style="background:none; border:none; box-shadow:none;">
					<font size="5">
					<div style="text-align:left">
						Source: <a href="http://www.iwocl.org/wp-content/uploads/iwocl-2016-boost-compute.pdf"> IWOCL Talk Jakub Szuppe </a>
					</div>
					</font>
				</section>
				<section>
					<font size="8">
					<div style="text-align:left">
						But ...
					</div>
					</font>
					<img src="boost_compute_performance2.png" height="100%" width="100%" style="background:none; border:none; box-shadow:none;">
					<font size="5">
					<div style="text-align:left">
						Source: <a href="https://arxiv.org/abs/1601.03144v1"> A Performance Comparison of Sort and Scan Libraries for GPUs -- B. Merry</a>
					</div>
					</font>
				</section>
				</section>
				<!-- ###################################################################
				     ##################################################################-->
				<!-- End -->
				<section>
				<h3>End</h3>
				</section>
				<!-- ###################################################################
					  END OF SECTIONS
				     ##################################################################-->
			</div>
		</div>
		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>
		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'convex', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
